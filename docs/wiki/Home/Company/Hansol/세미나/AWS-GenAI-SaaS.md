---
sticker: vault//이미지/개발 로고/TechIconSVG/AWS TechIcon SVG/Resource-Icons_02072025/Res_Artificial-Intelligence/Res-Amazon-SageMaker-Model-48.svg

slug: "AWS-GenAI-SaaS"
---
# AWS GenAI SaaS

:::note 해당 세션은 AWS Bedrock 을 중심으로 멀티 테넌트 상황에서 SasS 형 GenAI 구축 법을 설명하는 곳입니다.

:::

## AWS Amazon Bedrock

### AWS Bedrock?
Amazon Bedrock은 기초 모델(Foundation Models(FM)) 또는 대규모 언어 모델(Large Language Models(LLM))을 사용하여 생성형 AI 애플리케이션을 구축하고 확장하는 과정을 간소화하는 완전 관리형 서비스입니다. 

![Pasted-image-20250828080833.png](/img/이미지 창고/Pasted-image-20250828080833.png)

**AI21 Labs**, **Anthropic**, Cohere, **Meta**, Mistral AI, Stability AI 및 Amazon과 같은 선도적인 AI 기업들의 고성능 LLM에 접근할 수 있는 단일 API를 제공합니다.

Amazon Bedrock을 사용하면 다음과 같은 작업을 수행할 수 있습니다:
1. **LLM 실험 및 평가**: 다양한 LLM을 쉽게 실험하고 평가하여 유즈케이스에 가장 적합한 LLM을 찾습니다.
2. **LLM 커스터마이징**: 파인 튜닝(Fine-Tuning) 및 검색 증강 생성(Retrieval Augmented Generation(RAG))과 같은 기술을 사용하여 귀하의 데이터로 LLM을 비공개로 커스터마이징 합니다.
3. **Agent 구축**: 기업 시스템과 데이터 소스를 사용하여 작업을 실행할 수 있는 Agent를 만듭니다.
4. **서버리스 및 보안**: AWS 서비스를 사용하여 인프라를 관리하지 않고도 보안, 개인정보 보호 및 책임감 있는 AI를 보장하면서 생성형 AI 기능을 애플리케이션에 배포합니다.

즉, 정리한다면, 기존 LLM API 를 사용하면, GPT 라면 GPT, Gemini 라면 Gemini 만 사용이 가능했다면, 이제는 AWS 에서 제공하고 지원하는 모든 LLM을 사용자의 입맛에 맞게 선택하여 API를 사용 가능합니다.

아쉽게도 GPT, Gemini, Grok은 들어가있지 않지만, 클로드, Amazon 자체 AI 인 Nova 그리고 최근에 오픈소스화 된 GPT-OSS 또한 사용 가능합니다.

:::warning 하지만, 이 기능으로는 특정 비즈니스에서는 사용이 불가능합니다.
- 주로 이 모델들은 온라인에서 가용 가능한 데이터들만 학습을 진행했기 때문입니다.

:::

그래서 나오는 대안들이 RAG 방식 입니다.

## RAG

### RAG이란 무엇이며, 왜 사용되는가

검색 증강 생성(RAG)은 모델의 학습된 데이터외에도 신뢰할 수 있는 외부 지식 소스의 정보를 통합하여 LLM 결과를 개선하는 기술입니다.

RAG를 사용하면 LLM의 결과의 정확성, 관련성 및 유용성을 향상시키면서 비용 효율적으로 LLM을 활용할 수 있습니다. 
LLM에 외부 지식 소스를 보완함으로써 RAG는 모델의 응답이 최신이며 도메인에 특화되고 사실적으로 정확하도록 보장합니다.

사실상 RAG은 LLM의 효율성을 위한 기술입니다.

LLM 이 모든 데이터를 기업용 데이터를 모두 학습하면 제일 좋겠지만, 물리적으로 그러한 데이터까지 학습 시키기엔 자원적으로나 시간적으로나 효율적이지 못합니다.

그렇기 때문에, LLM에게 데이터는 제공해야하지만, 튜닝까지 필요하지 않을 시에는 이러한 RAG이라는 기술을 도입해서 효율성을 높이는 작업을 합니다.

:::note AWS 결국은 기업용 비즈니스 AI 에서 AI가 모든 데이터를 학습하여 훈련하는게 아닌, RAG 방식을 도입해서 보다 효율적으로 AI를 운용하는걸 목표로 삼았습니다.
- 결국 아래에 소개되는 모든 AWS Resource는 결국 RAG을 구현하기 위해서 사용되는 리소스들 입니다.

:::

### RAG의 핵심 데이터의 Vector 화
![Pasted-image-20250828110611.png](/img/이미지 창고/Pasted-image-20250828110611.png)
위 아키텍처에 대한 자세한 설명은 아래에서 하지만, 우선적으로 봤을 때는, Bedrock을 중심으로 수많은 리소스가 존재합니다.
위 리소스는 대부분은 Vector 데이터화를 일조하는데 사용됩니다
특히, **S3**, **Knowledge base** 이 두개가 그 역할에 일조하고 있습니다.

특히 위에 아키텍처에 대한 AWS 의 설명은 멀티 테넌트 RAG 아키텍처 라고 명명하고 있습니다.
어려운 말 처럼 보이지만 결국은 테넌트라는 말은 정의하기 나름입니다.

:::tip 테넌트란?
- 해당 아키텍트에서 테넌트란, 어플리케이션, 사용자, 시스템 등등을 통합해서 뜻하는 단어 입니다.
- 즉, 비즈니스 마다, 사용성 마다 다른 페르소나와 비슷한 말입니다.


:::

## 결론

멀티 테넌트의 핵심은 결국은 아키텍쳐도 중요한 대목이지만, 결국은 AWS의 아키텍트에서 보이듯 싶이, 각 테넌트 별로의 DATA는 다르게 가지가는 전략을 취합니다.

즉, 순수 Vector 데이터에 의미와 조건을 부여할 수 없기에, 각 섹터별로 논리적 혹은 물리적으로 데이터를 나누는게 현실적이라는 판단입니다.

쉽게 얘기한다면, 결국 **어떤 테넌트**가 오고, **어떤 기준으로 데이터를 쪼갤** 것인지, 그리고 **어떤 데이터를 Vector화**를 시킬 건지에 대한 논의가 먼저 진행이 되어야합니다.

어찌 보면 예전에 MSA와 그리 다르지 않다고 봅니다.
![Pasted-image-20250828111542.png](/img/이미지 창고/Pasted-image-20250828111542.png)
DB를 어떤 기준으로 쪼갤 것인가. 그리고 그 쪼갠 데이터를 어떤 식으로 표현 할 것인가? 혹은 보여줄 것인가?

MSA 역시도 DB를 잘 쪼개고, 각 Server 간 연결성을 강화 한다면, 엄청난 시너지를 내듯, 결국 AI 의 RAG 기술 또한 어떻게 데이터를 쪼개야하고, 쪼갠 데이터 끼리의 연결성은 어떻게 보장할 것인지에 따라서, 실제 AI 를 쓰는 Bedrock에서 어떤 모델을 선택할 수 있을지도 변하게 되는 것입니다.

:::tip 약간의 주관을 섞자면..
-  잘 만들고, AI 친화적인 데이터라면, 당연히 AI 모델에 대한 성능이 낮아도 될 것이고, 
- 데이터가 사람 친화적일수록 성능 좋은 LLM을 선택해야 할것 입니다.


:::
