---
sticker: vault//이미지/개발 로고/TechIconSVG/AWS TechIcon SVG/Resource-Icons_02072025/Res_Artificial-Intelligence/Res-Amazon-SageMaker-Model-48.svg

slug: "LLM을-활용-리스트"
---
# LLM에 대한 테스트

Gemma3를 기준으로 MacBook Air M2 16GB 가 로컬로 충분히 구동 되며,  `.md` 을 기반으로 테스트을 꽤 많이 진행하였습니다.

## Prompt 엔지니어링 방식

정말 단순한 데이터만으로 AI를 구동하기 위해서는 굳이 RAG 방식을 도입하지 않아도 된다.
Prompt만으로도 어느정도의 커버가 가능하지만, 생각보다 꽤 오래 걸린다는 것을 알수 잇다.

이유는 결국은 Gemma 자체도 꽤 큰 AI이기도 하면서, Prompt를 기반으로 한 데이터 또한 꽤 거대한 데이터 라고 인식되기 때문에, 매번 context를 입력할 때마다, Prompt를 지속적으로 스캔하기 때문에, 생각보다 오래 걸린다.

![스크린샷-2025-09-01-오후-12.48.58.png](/img/이미지 창고/스크린샷-2025-09-01-오후-12.48.58.png)
그래서 대규모 데이터가 필요한 곳에서는 비추 하는 방식이다.
그렇다면 대규모 데이터가 필요한 곳에서 쓸수 있는 방법은 RAG 방식이다.

아래는 RAG 방식으로 구현한 Gemma3의 구동 화면이다.
![스크린샷-2025-09-01-오후-6.41.59.png](/img/이미지 창고/스크린샷-2025-09-01-오후-6.41.59.png)

꽤 시간이 개선된게 눈에 보일 정도이다.
심지어, 데이터도 prompt만 구동했을 때 보다 데이터가 더 많은데 로컬에서도 8s 면 출력해준다.


그리고 `.md` 의 어떤 내용을 입력해서 데이터로 던져주냐에 따라 SLM이 대답하는 퀄리티 ,답변 속도, 답변 정확도가 정말 달라집니다.

## LLM을 기반으로 활용할 수 있는 리스트

LLM을 RAG 기반으로 현재 사내에서 활용할수 있는 리스트들을 추려본다면
- 표준웹 프레임워크 AI 에이전트
	- 문서 or 샘플 코드로 파편화 되어있는 코드와 설명을 llm을 통해서 한꺼번에 습득 및 예시 코드 출력 가능
	- 기존에 지속적으로 문의 했던 내용들에서 생겼던 개발 딜레이가 ai 질의로 딜레이 해결
	- 이 밖에서도 사용 설명서 혹은 docs에 대한 내용들을 AI 와 연동하여 채팅 봇을 만들 수 있음

- AIOps(AI for IT Operations)
	- Prometheus를 기반으로한 서버의 Metric 데이터를 기반으로 LLM 기능 극대화
	- LLM을 기반으로 한 서버 모니터링 
		- 기술 문서나 과거 장애 이력 등을 빠르게 대조 후 대처법을 제시함
		- 예: "CPU 사용률이 80%를 넘으면 RabbitMQ 큐 사이즈를 확인하라"는 내용의 문서를 찾아냅니다.

- Application 로그 분석 LLM
	- 기존 서버 접속 후 로그 파일 접속후 에러 로그를 찾아다니던 예전과 다르게, LLM을 통해서 텍스트로 에러 로그를 추적할수 있음
	- 위 서버와 마찬가지로, 예전 사례와 비교해서 해당 에러 로그를 빠르게 해결 할 수 있도록 대안을 제시할 수 있음
	- 로그를 기반으로 추적을 자연어로 사용 가능
		- 예 : 어제 새벽 2시에서 4시 사이에 접속한 사용자의 리스트를 보여줘

- 권한 기반 AI
	- 권한 기반으로 AI를 구축하기 위해서는 Vector 데이터를 권한 기준으로 나눠서 구조화를 해야합니다.
	- 즉, 권한을 기반으로 Vector 데이터를 분리 해야하므로, 무거운 LLM을 하나로 벡터 데이터를 지속적으로 교체하는 행위보단
	- SLM을 역할별로 여러개를 구성해서, Vector 데이터를 쪼개는 작업이 더 효율적입니다.
	- 복잡한 추론작업 혹은 계산 작업이 필요하지 않다면, LLM은 자원 및 성능에 대한 비효율성이 비약적으로 커짐
	- 당연하게도 모든 권한이 AI를 필요로 하지 않음, 그리고 권한별로 해당 자원 할당시, 비용 증가
		-> 대안으로는 해당 권한을 묶어서 월별 결제로 제공하면 안정적 수익화 가능

- 제조 및 스마트 팩토리 (Manufacturing)
	- 사용자 혹은 회사에서 정한 정상값과 비정상값을 prompt화 하여서, 해당 데이터를 기반으로 몇시 몇분에 해당 값을 넘었는지 이런 것들을 출력 가능
	- 고성능 LLM을 사용한다면, 이런 데이터들을 PDF, Excel 을 출력할 수 있다
	- 작업 메뉴얼 또한 RAG 데이터로 활용 가능
	- 실제 웹 시스템에서 오류, 혹은 특이사항, 특이 로그, 특이 접속 등을 상단 application LLM을 통해서 서버의 접속 할 필요 없이 추적 및 출력 가능
	- 

- 안전 법률 데이터 
	- 사내 안전 관리 시스템에서 제일 복잡하고 미묘하게 작용하는 법률에 대한 부분을 RAG 화 하여서, 자주 까먹는 법률에 대한 어시스트를 하는 AI를 개발
	- 해당 내용은 단순 법률에 관련한 기반이기에, SLM으로 충분히 구현 가능





